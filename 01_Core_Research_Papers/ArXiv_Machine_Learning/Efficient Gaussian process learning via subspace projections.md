# Efficient Gaussian process learning via subspace projections

**출처:** [ArXiv_Machine_Learning](https://arxiv.org/abs/2601.16332)

## 요약
arXiv:2601.16332v1 Announce Type: new
Abstract: We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random projections on the unit sphere. We show the superiority of the PL, in terms of accuracy and computational efficiency, over the exact GP training and the variational free energy approach to sparse GPs over different optimisers, kernels and datasets of moderately large sizes.
