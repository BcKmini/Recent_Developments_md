# Video Friday: Gemini Robotics Improves Motor Skills

**출처:** [IEEE_Spectrum_Robotics](https://spectrum.ieee.org/video-friday-google-gemini-robotics)

## 요약
![](https://spectrum.ieee.org/media-library/robotic-arms-manipulate-objects-and-grapes-humanoid-robot-by-apptronik.webp?id=61659549&width=1245&height=700&coordinates=0%2C0%2C0%2C0)  
  

Video Friday is your weekly selection of awesome robotics videos, collected by your friends at *IEEE Spectrum* robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please [send us your events](mailto:automaton@ieee.org?subject=Robotics%20event%20suggestion%20for%20Video%20Friday) for inclusion.

##### [CoRL 2025](https://www.corl.org/): 27–30 September 2025, SEOUL

##### [IEEE Humanoids](https://2025humanoids.org/): 30 September–2 October 2025, SEOUL

##### [World Robot Summit](https://worldrobotsummit.org/en/): 10–12 October 2025, OSAKA, JAPAN

##### [IROS 2025](https://www.iros25.org/): 19–25 October 2025, HANGZHOU, CHINA

Enjoy today’s videos!

> *[Gemini Robotics](https://spectrum.ieee.org/gemini-robotics) 1.5 is our most capable vision-language-action (VLA) model, which turns visual information and instructions into motor commands for a robot to perform a task. This model thinks before taking action and shows its process, helping robots assess and complete complex tasks more transparently. It also learns across embodiments, [accelerating skill learning](https://spectrum.ieee.org/deepmind-table-tennis-robots).*

[ [Google DeepMind](https://deepmind.google/discover/blog/gemini-robotics-15-brings-ai-agents-into-the-physical-world/) ]

> *A simple “force pull” gesture brings Carter straight into her hand. This is a fantastic example of how an intuitive interaction can transform complex technology into an extension of our intent.*

[ [Robust.ai](https://www.robust.ai/) ]

I can’t help it, I feel bad for this poor little robot.

[ [Urban Robotics Laboratory, KAIST](https://dreamflex.github.io/) ]

Hey look, no legs!

[ [Kinisi Robotics](https://www.kinisi.com/) ]

> *Researchers at the University of Michigan and Shanghai Jiao Tong University have developed a soft robot that can crawl along a flat path and climb up vertical surfaces using its unique origami structure. The robot can move with an accuracy typically seen only in rigid robots.*

[ [University of Michigan Robotics](https://robotics.umich.edu/news/2025/sparc-climbing-origami-robot/) ]

> *Unitree G1 has learned the “antigravity” mode: Stability is greatly improved under any action sequence, and even if it falls, it can quickly get back up.*

[ [Unitree](https://www.unitree.com/g1/) ]

> *Kepler Robotics has commenced mass production of the K2 Bumblebee, the world’s first commercially available humanoid robot powered by Tesla’s hybrid architecture.*

[ [Kepler Robotics](https://www.gotokepler.com/) ]

> *Reinforcement learning (RL)-based legged locomotion controllers often require meticulous reward tuning to track velocities or goal positions while preserving smooth motion on various terrains. Motion imitation methods via RL using demonstration data reduce reward engineering but fail to generalize to novel environments. We address this by proposing a hierarchical RL framework in which a low-level policy is first pretrained to imitate animal motions on flat ground, thereby establishing motion priors. Real-world experiments with an ANYmal-D quadruped robot confirm our policy’s capability to generalize animal-like locomotion skills to complex terrains, demonstrating smooth and efficient locomotion and local navigation performance amid challenging terrains with obstacles.*

[ [ETHZ RSL](https://anymalprior.github.io/) ]

I think we have entered the “differentiation through novelty” phase of robot vacuums.

[ [Roborock](https://us.roborock.com/products/roborock-qrevo-curv-x) ]

> *In this work, we present Kinethreads: a new full-body haptic exosuit design built around string-based motor-pulley mechanisms, which keeps our suit lightweight (less than 5 kilograms), soft and flexible and quick-to-wear (in less than 30 seconds), comparatively low-cost (about US $400), and yet capable of rendering expressive, distributed, and forceful (up to 120 newtons) effects.*

[ [ACM Symposium on User Interface and Software Technology](https://programs.sigchi.org/uist/2025/program/content/206935) ]

> *In this episode of the IBM AI in Action podcast, Aaron Saunders, chief technology officer of Boston Dynamics, delves into the transformative potential of AI-powered robotics, highlighting how robots are becoming safer, more cost-effective and widely accessible through robotics as a service (RaaS).*

[ [IBM](https://www.ibm.com/think/podcasts/ai-in-action) ]

> *This Carnegie Mellon RI Seminar is by Michael T. Tolley from the University of California, San Diego, on biologically inspired soft robotics.*

> *Robotics has the potential to address many of today’s pressing problems in fields ranging from health care to manufacturing to disaster relief. However, the traditional approaches used on the factory floor do not perform well in unstructured environments. The key to solving many of these challenges is to explore new, nontraditional designs. Fortunately, nature surrounds us with examples of novel ways to navigate and interact with the real world. Dr. Tolley’s Bioinspired Robotics and Design Lab seeks to borrow the key principles of operation from biological systems and apply them to robotic design.*

[ [Carnegie Mellon University Robotics Institute](https://www.ri.cmu.edu/event/biologically-inspired-soft-robotics/) ]
