# Video Friday: Bipedal Robot Stops Itself From Falling

**출처:** [IEEE_Spectrum_Robotics](https://spectrum.ieee.org/video-friday-bipedal-robot)

## 요약
![](https://spectrum.ieee.org/media-library/prototype-robot-next-to-a-digital-model-both-with-rounded-bodies-and-dome-shaped-heads.png?id=62822757&width=1200&height=800&coordinates=167%2C0%2C168%2C0)  
  

Video Friday is your weekly selection of awesome robotics videos, collected by your friends at *IEEE Spectrum* robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please [send us your events](mailto:automaton@ieee.org?subject=Robotics%20event%20suggestion%20for%20Video%20Friday) for inclusion.

##### [ICRA 2026](https://2026.ieee-icra.org/): 1–5 June 2026, VIENNA

Enjoy today’s videos!

This is one of the best things I have ever seen.

[ [Kinetic Intelligent Machine LAB](https://publish.illinois.edu/kimlab2020/) ]

> *After years of aggressive testing and pushing the envelope with U.S. Army and Marine Corps partners, the [Robotic Autonomy in Complex Environments with Resiliency](https://spectrum.ieee.org/nasa-jpl-team-costar-darpa-subt-urban-circuit-systems-track) (RACER) program approaches its conclusion. But the impact of RACER will reverberate far beyond the program’s official end date, leaving a legacy of robust autonomous capabilities ready to transform military operations and inspire a new wave of private-sector investment.*

[ [DARPA](https://www.darpa.mil/news/2026/racer-finish-line) ]

Best-looking humanoid yet.

[ [Kawasaki](https://kawasakirobotics.com/eu-africa/news/20200714-01/) ]

> *COSA (Cognitive OS of Agents) is a physical-world-native Agentic OS that unifies high-level cognition with whole-body motion control, enabling humanoid robots to think while acting in real environments. Powered by COSA, Oli becomes the first humanoid agent with both advanced loco-manipulation and high-level autonomous cognition.*

[ [LimX Dynamics](https://www.limxdynamics.com/en) ]

Thanks, Jinyan!

> *The 1X World Model’s latest update is a paradigm shift in robot learning: NEO now uses a physics-grounded video model (World Model) to turn any voice or text prompt into fully autonomous action, even for completely novel tasks and objects NEO has never seen before. By leveraging internet-scale video data fine-tuned on real robot experience, NEO can visualize future actions, predict outcomes, and execute them with humanlike understanding–all without prior examples. This marks the critical first step in NEO being able to collect data on its own to master new tasks all by itself.*

[ [1X](https://www.1x.tech/) ]

I’m impressed by the human who was mocapped for this.

[ [PNDbotics](https://pndbotics.com/) ]

> *We introduce the GuideData Dataset, a collection of qualitative data, focusing on the interactions between guide dog trainers, visually impaired (BLV) individuals, and their guide dogs. The dataset captures a variety of real-world scenarios, including navigating sidewalks, climbing stairs, crossing streets, and avoiding obstacles. By providing this comprehensive dataset, the project aims to advance research in areas such as assistive technologies, robotics, and human-robot interaction, ultimately improving the mobility and safety of visually impaired people.*

[ [DARoS Lab](https://guidedogrobot-hgidataset.github.io/) ]

> *Fourier’s desktop Care-Bot prototype is gaining much attention at [CES 2026](https://spectrum.ieee.org/robots-ces-2026)! Even though it’s still in the prototype stage, we couldn’t wait to share these adorable and fun interaction features with you.*

[ [Fourier](https://www.fftai.com/) ]

> *Volcanic gas measurements are critical for understanding eruptive activity. However, harsh terrain, hazardous conditions, and logistical constraints make near-surface data collection extremely challenging. In this work, we present an autonomous legged robotic system for volcanic gas monitoring, validated through real-world deployments on Mount Etna. The system combines a quadruped robot equipped with a quadrupole mass spectrometer and a modular autonomy stack, enabling long-distance missions in rough volcanic terrain.*

[ [ETH Zurich RSL](https://leggedrobotics.github.io/etna-expedition/) ]

> *Humanoid and Siemens successfully completed a POC testing humanoid robots in industrial logistics. This is the first step in the broader partnership between the companies. The POC focused on a tote-to-conveyor destacking task within Siemens’s logistics process. HMND 01 autonomously picked, transported, and placed totes in a live production environment during a two-week on-site deployment at the Siemens Electronics Factory in Erlangen.*

[ [Humanoid](https://thehumanoid.ai/) ]

> *Four Growers, a category leader in intelligent ag-tech platforms, developed the GR-200 [robotic harvesting](https://spectrum.ieee.org/autonomous-robots-plant-tend-and-harvest-entire-crop-of-barley) platform, powered by FANUC’s LR Mate robot. The system combines AI-driven vision and motion planning to identify and harvest ripe tomatoes with quick precision.*

[ [FANUC](https://www.fanucamerica.com/case-studies/automating-agriculture-greenhouse-turns-to-robots-for-tomato-harvesting) ]

> *Columbia Engineers built a robot that, for the first time, is able to learn facial lip motions for tasks such as speech and singing. In a new study published in Science Robotics, the researchers demonstrate how their robot used its abilities to articulate words in a variety of languages, and even sing a song out of its AI-generated debut album, “hello world\_.” The robot acquired this ability through observational learning rather than via rules. It first learned how to use its 26 facial motors by watching its own reflection in the mirror before learning to imitate human lip motion by watching hours of YouTube videos.*

[ [Columbia](https://www.engineering.columbia.edu/about/news/robot-learns-lip-sync) ]

Roborock has some odd ideas about what lawns are like.

[ [Roborock](https://newsroom.roborock.com/gl/news/ces-2026-roborock-releases-the-world-s-first-robotic-vacuum-with-wheel-leg-architecture-as-it-joins-hands-with-real-madrid-football-club-) ]

> *DEEP Robotics’ quadruped robots demonstrate coordinated multi-module operations under unified command, tackling complex and dynamic firefighting scenarios with agility and precision.*

[ [DEEP Robotics](https://www.deeprobotics.us/) ]

> *Unlike statically stable wheeled platforms, humanoids are dynamically stable, requiring continuous active control to maintain balance and prevent falls. This inherent instability presents a critical challenge for functional safety, particularly in collaborative settings. This presentation will introduce Synapticon’s POSITRON platform, a comprehensive solution engineered to address these safety-critical demands. We will explore how its integrated hardware and software enable robust, certifiable safety functions that meet the highest industrial standards, providing key insights into making the next generation of humanoid robots safe for real-world deployment.*

[ [Synapticon](https://www.synapticon.com/en/products/positron-safety) ]

> *The University of California, Berkeley, is world-famous for its AI developments, and one big name behind them is [Ken Goldberg](https://spectrum.ieee.org/ken-goldberg-discusses-telerobots-androids-and-heidegger). Longtime professor and lifelong artist, Ken is all about deep learning while staying true to “good old-fashioned engineering.” Hear Ken talk about his approach to vision and touch for robotic surgeries and how robots will evolve across the board.*

[ [Waymo](https://www.youtube.com/playlist?list=PLCkt0hth826G9AtnOrQsPbKKD5JmdaMXb) ]
