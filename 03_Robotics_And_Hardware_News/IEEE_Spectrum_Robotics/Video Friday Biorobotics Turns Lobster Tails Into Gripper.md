# Video Friday: Biorobotics Turns Lobster Tails Into Gripper

**출처:** [IEEE_Spectrum_Robotics](https://spectrum.ieee.org/lobster-biorobotics)

## 요약
![](https://spectrum.ieee.org/media-library/robotic-gripper-with-feather-like-fingers-delicately-holds-a-brown-mushroom-on-a-black-background.jpg?id=62284894&width=1245&height=700&coordinates=0%2C1%2C0%2C1)  
  

Video Friday is your weekly selection of awesome robotics videos, collected by your friends at *IEEE Spectrum* robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please [send us your events](mailto:automaton@ieee.org?subject=Robotics%20event%20suggestion%20for%20Video%20Friday) for inclusion.

##### [ICRA 2026](https://2026.ieee-icra.org/): 1–5 June 2026, VIENNA

Enjoy today’s videos!

> *EPFL scientists have integrated discarded crustacean shells into robotic devices, leveraging the strength and flexibility of natural materials for robotic applications.*

[ [EPFL](https://news.epfl.ch/news/bio-hybrid-robots-turn-food-waste-into-functiona-2/) ]

Finally, a good [humanoid robot](https://spectrum.ieee.org/humanoid-robots) demo!

Although having said that, I never trust videos demos where it works really well once, and then just pretty well every other time.

[ [LimX Dynamics](https://www.limxdynamics.com/en/oli) ]

Thanks, Jinyan!

I understand how these structures work, I really do. But watching something rigid extrude itself from a flexible reel will always seem a little magical.

[ [AAAS](https://www.eurekalert.org/news-releases/1107385) ]

Thanks, Kyujin!

I’m not sure what “industrial grade” actually means, but I want robots to be “automotive grade,” where they’ll easily operate for six months or a year without any maintenance at all.

[ [Pudu Robotics](https://www.pudurobotics.com/en/products/d5) ]

Thanks, Mandy!

When you start to suspect that your [robotic EV charging](https://spectrum.ieee.org/mobile-ev-charging-robot) solution costs more than your car.

[ [Flexiv](https://www.flexiv.com/case-studies/ev_charging_solution) ]

Yeah uh if the application for this humanoid is actually making robot parts with a hammer and anvil, then I’d be impressed.

[ [EngineAI](https://www.engineai.com.cn/product-t800) ]

> *Researchers at Columbia Engineering have designed a robot that can learn a human-like sense of neatness. The researchers taught the system by showing it millions of examples, not teaching it specific instructions. The result is a model that can look at a cluttered tabletop and rearrange scattered objects in an orderly fashion.*

[ [Paper](https://arxiv.org/html/2310.04566v3) ]

Why haven’t we seen this sort of thing in humanoid robotics videos yet?

[ [HUCEBOT](https://www.inria.fr/en/hucebot) ]

While I definitely appreciate in-the-field testing, it’s also worth asking to what extent your robot is actually being challenged by the in-the-field field that you’ve chosen.

[ [DEEP Robotics](https://www.deeprobotics.cn/en) ]

> *Introducing HMND 01 Alpha Bipedal — autonomous, adaptive, designed for real-world impact. Built in 5 months, walking stably after 48 hours of training.*

[ [Humanoid](https://thehumanoid.ai/product/) ]

Unitree says that “this is to validate the overall reliability of the robot” but I really have to wonder how useful this kind of reliability validation actually is.

[ [Unitree](https://www.unitree.com/) ]

This University of Pennsylvania GRASP on Robotics Seminar is by Jie Tan from Google DeepMind, on “Gemini Robotics: Bringing AI into the Physical World.”

> *Recent advancements in large multimodal models have led to the emergence of remarkable generalist capabilities in digital domains, yet their translation to physical agents such as robots remains a significant challenge. In this talk, I will present Gemini Robotics, an advanced Vision-Language-Action (VLA) generalist model capable of directly controlling robots. Furthermore, I will discuss the challenges, learnings and future research directions on robot foundation models.*

[ [University of Pennsylvania GRASP Laboratory](https://www.grasp.upenn.edu/events/fall-2025-grasp-on-robotics-jie-tan/) ]
