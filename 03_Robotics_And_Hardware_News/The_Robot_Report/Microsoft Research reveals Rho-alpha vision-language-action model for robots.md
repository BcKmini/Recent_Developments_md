# Microsoft Research reveals Rho-alpha vision-language-action model for robots

**출처:** [The_Robot_Report](https://www.therobotreport.com/microsoft-research-reveals-rho-alpha-vision-language-action-model-for-robots/)

## 요약
The Rho-alpha model incorporates sensor modalities such as tactile feedback and is trained with human guidance, says Microsoft.

The post [Microsoft Research reveals Rho-alpha vision-language-action model for robots](https://www.therobotreport.com/microsoft-research-reveals-rho-alpha-vision-language-action-model-for-robots/) appeared first on [The Robot Report](https://www.therobotreport.com).
