# [DAN25] 기술세션 영상이 모두 공개되었습니다.

**출처:** [Naver_D2](https://d2.naver.com/news/9333656)

## 요약
![](https://d2.naver.com/content/images/2025/11/---------.gif)

지난 11월 6일, 7일 양일간 진행된 팀네이버 컨퍼런스 DAN25에서는 네이버의 기술뿐만 아니라 크리에이티브, 서비스와 비즈니스를 유기적으로 융합해 일상의 작은 변화부터 새로운 생태계로의 도약까지, 끝없이 확장되는 경험의 로드맵을 함께 나누는 자리로 진행되었습니다.

**현장에서는 AI 에이전트, 소버린 AI, AX 등 네이버가 제시하는 미래 전략과 실제 서비스·비즈니스에 적용된 다양한 사례들이 공유**되며, 참가자들이 변화된 사용자 경험을 직접 확인하고 인사이트를 얻을 수 있었습니다.

컨퍼런스에서 선보인 다양한 세션과 발표들은 많은 관심을 모았는데요, 현장의 그 생생한 분위기를 온라인에서도 만나볼 수 있도록 모든 발표영상이 [DAN25 홈페이지](https://dan.naver.com/25)와 [NAVER 네이버 TV 채널](https://tv.naver.com/playnaver)에 공개 되었습니다.

![](https://d2.naver.com/content/images/2025/11/-----------2025-11-27-------11-05-01.png)

#### 총 35개의 기술세션 중

**오프라인 현장에서 가장 참여율(참석 및 질문)이 높았던 기술 세션 5개**를 뽑아보았습니다.

### **[DAN25 Tech 세션 TOP 5]**

#### [**1. 네이버 PersonA - 지금 나를 이해하는 AI (부제 : LLM 기반 사용자 메모리 구축과 실시간 사용자 로그 반영 시스템 구현)**\_NAVER 발견/탐색 프로덕트 임홍준, 김창봉, 최수진 님](https://dan.naver.com/25/sessions/713)

ChatGPT, Google Gemini와 같은 대화형 AI 서비스를 사용해 보면, 바로 이전 대화만 기억하는 것이 아니라, 수개월간의 대화 기록을 요약·저장하여 사용자와의 대화 맥락을 이어가는 모습을 볼 수 있습니다. 또한 ‘메모리’ 보기 기능을 통해, AI가 나에 대해 무엇을 기억하고 있는지도 확인할 수 있습니다.

네이버는 대화형 AI 서비스는 아닙니다. 그럼에도 불구하고, 사용자는 네이버의 다양한 서비스를 이용하면서 자신에 대한 수많은 단서를 남기고 있습니다. 직접적인 대화는 아니지만, 이러한 파편적인 기록들을 사용자와 네이버 간의 ‘간접적인 대화’로 보고, 이를 기반으로 사용자 메모리를 구축하려는 프로젝트가 바로 네이버 PersonA입니다.

네이버 PersonA 프로젝트에서는 사용자 메모리를 구축하기 위해 대규모 언어모델(LLM)을 적극 활용했습니다. 또한 적절한 시점에, 사용자에게 의미 있는 제안을 전달하기 위해 LLM의 추론 능력을 결합했습니다.

이번 발표에서는 LLM을 활용한 네이버의 사용자 메모리 구축 과정과, 이를 기반으로 제안 서비스를 어떻게 설계하고 구현했는지 공유합니다. 그 과정에서 마주한 고민들, 여러 선택지들 사이에서 해법을 찾아간 과정, 그리고 대규모 사용자에게 실시간 로그를 반영하며 서비스를 안정적으로 제공하기 위해 어떤 기술적·서비스적 대안을 선택했는지도 함께 말씀드리겠습니다.

아직 초기 단계이지만, 네이버는 단계적인 로드맵을 가지고 AI 에이전트 서비스로 진화해 나가고 있습니다. 이번 프로젝트는 그 의지를 담은 실험적이면서도 중요한 시도라 할 수 있습니다.

#### [**2. 데이터 속 숨은 트렌드, LLM이 답하다 : 랭킹 기반 플레이스 트렌드 분석 시스템**\_NAVER 플레이스 프로덕트 김현우, 손재원 님](https://dan.naver.com/25/sessions/681)

"지금 사람들이 가장 많이 찾는 장소는 어디일까요?" 본 발표에서는 실시간 사용자 데이터를 기반으로 '지금 뜨는 장소'를 찾아내는 랭킹 기반 플레이스 트렌드 분석 시스템을 소개합니다.

단순히 많이 찾는 곳을 넘어, '급등'과 '지속'의 균형을 맞춘 랭킹 알고리즘을 통해 진정으로 의미 있는 트렌드를 포착하는 노하우를 공유합니다. 더 나아가 텍스트 마이닝과 LLM을 활용하여 "왜 이 장소가 지금 뜨는가?"에 대한 이유까지 키워드로 추출하는 과정을 살펴봅니다.

데이터 속 숨겨진 트렌드를 발견하고, 그 이유까지 설명 가능한 인사이트를 얻어가는 시간을 가져보세요.

#### [**3. 검색 서비스에 최적화된 LLM 만들기: 데이터, 학습, 서비스 적용 사례**\_NAVER Cloud HCX Application 신원광, 권유환 님. NAVER 검색 플랫폼 권오준, 백지혜 님](https://dan.naver.com/25/sessions/724)

범용 LLM은 강력하지만 매일 수십억 건의 질문과 답을 다루는 실제 검색 서비스에 그대로 적용하기에는 한계가 있다. 본 발표에서는 "검색 서비스 특화 LLM"을 만들고 실제 서비스에 적용해본 경험담을 공유한다. 검색 로그에서 출발한 데이터 가공 레시피 적용과 다양한 데이터 조합 실험, 특히 기존 범용 성능을 유지하면서도 서비스 맞춤 기능을 끌어올린 실험 결과와 데이터 최적화 노하우를 공유한다.

실제 서비스 적용 관점에서는 보다 신뢰성있는 검색 결과를 사용자에게 제공하기 위한 AuthGR과 전통적인 정보 검색 과정을 하나로 통합해 제시하는 AI briefing 을 소개한다. 이를 통해 범용 LLM 대비 검색 서비스 특화 모델의 효용성을 확인할 수 있으며, 네이버가 검색 품질 개선을 위해 갖고있는 고민과 앞으로의 방향성을 엿볼 수 있다.

#### [**4. 실시간 추천-CRM 통합 모델로 완성하는 개인화** UX\_NAVER WEBTOON ML Platform 김회인, 이성훈 님](https://dan.naver.com/25/sessions/690)

네이버 시리즈는 개인화 UX를 위해 추천부터 CRM까지 다양한 영역에 ML 모델을 활용하고 있습니다. 하지만 여러 모델들이 추가되면서 모델 관리의 복잡성이 커지고, 모델 간 일관성을 유지하기 어려운 한계가 드러났습니다.

동시에 CRM 모델 중 일부는 실시간으로 처리되지 않는 기능이 있어 개선이 필요한 상황이었습니다. 이러한 문제를 해결하기 위해 모델 개발 관점에서는 추천과 CRM 모델을 하나의 통합 프레임워크로 설계하기로 결정하였고, 모델 서빙 관점에서는 모든 모델의 결과를 실시간으로 받아오기 위해 API 기반 서빙 아키텍처를 구축하기로 결정하였습니다.

본 발표에서는 네이버 시리즈에 실제 적용된 사례를 중심으로, 추천-CRM 모델 통합 과정과 배치 기반에서 실시간 추론 체계로 전환한 경험을 공유합니다. 대규모 서비스 환경에서 개인화 경험을 고도화하기 위한 모델링/시스템 설계의 실제적인 고민과 해법을 함께 나누고자 합니다.

#### [**5. 하루 수백억 건을 처리하는 똑똑한 로그 파이프라인 만들기: 비용·성능·안정성 삼박자**\_NAVER 검색 플랫폼 김완호 님](https://dan.naver.com/25/sessions/693)

네이버 전사 로그(최대 초당 수백만건, 하루 수백억건의 로그)를 수집/처리하는 로그 파이프라인 Logiss를 소개하고, Logiss에서 겪은 문제점들과 해결책들을 공유합니다.

Storm + kafka 환경에서 multi topology를 적용하는 방법과 이를 통해 안정적인 무중단 배포가 가능해진 파이프라인과 지능형 파이프라인의 도입으로 낮시간의 피크 트래픽을 한가한 시간으로 분산시킨 방법, 장애 상황에서 로그의 우선 순위에 따른 차등된 처리 방식, 샘플링 기능으로 저장소를 효율적으로 이용할 수 있게된 방법을 알려드립니다.

#### [[DAN25] Tech 세션 영상 더 보기 >>](https://dan.naver.com/25/sessions#DAY2)
